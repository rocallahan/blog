---
layout: "post"
title: "Speeding Up `dwarfdump` With Rust"
date: "2018-03-29 01:44:00 +0000"
permalink: "/2018/03/speeding-up-dwarfdump-with-rust.html"
---
<p>Writing a debugger for C++ on Linux, you spend a lot of time examining pretty-printed DWARF debug information using tools like <tt>readelf</tt>, <tt>objdump</tt> or <tt>dwarfdump</tt>. Unfortunately this can be quite slow. For Firefox's <tt>libxul.so</tt>, dwarfdump's pretty-printed output of just the main <tt>.debug_info</tt> is 25GiB. The standard objdump and readelf tools take about three minutes to print it to <tt>/dev/null</tt>.
<p>The Rust <a href="https://github.com/gimli-rs/gimli">gimli</a> crate includes a Rust-implemented version of dwarfdump. Initially it took about eight minutes to dump libxul, although the comparison is unfair because dwarfdump dumps more data than readelf. I decided to try to speed dwarfdump up. <strong>TL;DR: I reduced the dump time from 506s to 26s by fixing some simple issues and taking advantage of Rust "fearless parallelism".</strong> I think there are interesting opportunities for speeding up many kinds of command-line tools using Rust and parallelism.
<p>Initially gimli dwarfdump was using <tt>println!</tt> to print every line of output. Every <tt>println!</tt> call temporarily locks the Rust stdout stream and performs a <tt>write</tt> system call, even when redirected to a file. This is extremely inefficient; it's much more efficient to buffer output so multiple lines are written with each system call. Since dwarfdump only used one thread, it can take the lock at the start and hold it permanently. <a href="https://github.com/gimli-rs/gimli/commit/ae191fd3e830aa46a0ade0110bc406b04d119ef8">These changes</a> reduced the run time to 215s.
<p>I did some profiling to look for hotspots amenable to micro-optimizations. I found that we spent a lot of CPU time in Rust's formatted-string padding code. dwarfdump used right-padding formatting of an empty string ("<tt>{:indent$}</tt>") to insert a specified number of spaces to indent each line. This is quite slow because the padding implementation writes the padded value to a temporary buffer, measures the length of the resulting string, and then writes the buffered value and the padding bytes. <a href="https://github.com/gimli-rs/gimli/commit/8a023cc5f8ec324b452b245c57357a59dd049e84">I changed</a> dwarfdump to indent by printing slices from a large string of spaces, reducing the run time to 142s. I also found that where some non-empty string tokens were being right-padded, we could speed things up emitting the padding as a string slice, taking advantage of the fact that these are static strings whose lengths we know. <a href="https://github.com/gimli-rs/gimli/commit/f138c5beb88cba7c1cbfac09b2dc91ab69fd53a3">That</a> reduced the run time to 99s.
<p>There are probably opportunities to improve the performance of Rust formatted text output by combining static knowledge of the format string and the types and other details of the parameters.
<p>I then turned to parallelism. dwarfdump prints the contents of <tt>.debug_info</tt> by looping over each compilation unit, and this is easy to do in parallel &mdash; in Rust, at least. In Rust, a method that takes an immutable <tt>&self</tt> reference guarantees it can be called safely on the same object from multiple threads, so it's evident from a library's API types whether and how it can be used with multiple threads, and the compiler checks your usage. Better still, since immutability is the default, in practice Rust libraries tend to work well with multithreading, and gimli is no exception.
<p>One important detail is that we want to output the results for compilation units in the correct order: the output for a compilation unit has to be buffered and printed to stdout after the output for all previous compilation units. You don't want to buffer the output of too many compilation units at once; each of those buffers can be tens of megabytes. I created a <a href="https://github.com/gimli-rs/gimli/commit/fef4e3d44c8df1e4a5b95667a07ad1545738b701#diff-1ee82a361e2e263ee3a88aba5961be3bR74">parallel-output</a> utility function to handle that. It assigns compilation units to a fixed number of worker threads (N) in a strict round-robin order and ensures that a worker thread doesn't start working on a new compilation unit until the results for its previous compilation unit have been printed. Thus at most N output buffers are required. With eight worker threads (for my quad-core, eight-hardware-threads Skylake laptop) this reduced the run time to 26s.
<p>Even with a single worker thread, run time dropped to 77s; some of the improvement actually came from changing writes from a <tt>BufWriter</tt> to a <tt>Vec&lt;u8&gt;</tt>. That may be due to <tt>io::Result</tt> error propagation and checking. Two threads give 47s, and four threads give 30s. Exceeding the physical cores provides negligible returns.
<p>At peak performance gimli dwarfdump produces 1GB of output per second. It's interesting that even for relatively simple pretty-printing and such high data volume, serialized large writes to stdout are not the bottleneck. This suggests that even simple Unixy stdio-pipeline tools might benefit from internal parallelism.
<p><img src="/assets/images/Dwarfdump.png" title="chart showing performance improvements" width="900" height="551">
<p>Achieving this performance by improving existing C tools would have been a lot more difficult than with gimli and Rust. There's no way to be sure that the relevant DWARF processing code, e.g. <tt>binutils/dwarf.c</tt>, is safe for use on multiple threads. (Given the presence of many unadorned static variables, it probably isn't.) Efficiently switching output backends would have been more difficult than in Rust, where it's idiomatic to parameterize output code on the static type of the output backend, e.g. <tt>fn dump_info&lt;W: Writer&gt;(w: &mut W, ...)</tt>.