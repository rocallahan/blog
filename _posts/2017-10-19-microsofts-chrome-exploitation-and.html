---
layout: "post"
title: "Microsoft's Chrome Exploitation And The Limitations Of Control Flow Integrity"
date: "2017-10-18 23:20:00 +0000"
categories: "Mozilla"
permalink: "/2017/10/microsofts-chrome-exploitation-and.html"
---
<p>Microsoft <a href="https://blogs.technet.microsoft.com/mmpc/2017/10/18/browser-security-beyond-sandboxing/">published</a> an interesting blog post about exploiting a V8 bug to achieve arbitrary code execution in a Chrome content sandbox. They rightly point out that then even if you don't escape the sandbox, you can break important Web security properties (e.g., assuming the process is allowed to host content from more than one origin, you can break same-origin restrictions). However, the message we're supposed to take away from this article is that Microsoft's CFI would prevent similar bugs in Edge from having the same impact. I think that message is basically wrong.
<p>The problem is, once you've achieved arbitrary memory read/write from Javascript, it's very likely you can break those Web security properties without running arbitrary machine code, without using ROP, and without violating CFI at all. For example if you want to violate same-origin restrictions, your JS code could find the location in memory where the origin of the current document is stored and rewrite it to be a different origin. In practice it would quite a lot more complicated than that, but the basic idea should work, and once you've implemented the technique it could be used to exploit any arbitrary read/write bug. It might even be easier to write some exploits this way than using traditional arbitrary code execution; JS is a more convenient programming language than ROP gadgets.
<p>The underlying technical problem is that once you've achieved arbitrary read/write you can almost completely violate data-flow integrity within the process. As I <a href="/2017/10/type-safety-and-data-flow-integrity.html">recently wrote</a>, DFI is extremely important and (unlike CFI) it's probably impossible to dynamically enforce with low overhead in the presence of arbitrary read/write, with any reasonable granularity.
<p>I think there's also an underlying cultural problem here, which is that traditionally "Remote Code Execution" &mdash; of unconstrained machine code &mdash; has been the gold standard for a working exploit, which is why techniques to prevent that, like CFI, have attracted so much attention. But Javascript (or some other interpreter, or even some Turing-complete interpreter-like behavior) armed with an arbitrary memory read/write primitive is just as bad in a lot of cases.
<div class='comments'><h2>Comments</h2>
<div class='comment'>
<div class='author'>Unknown</div>
<div class='content'>They might be referring to the per-tab hypervisor that was just launched today in ie/edge which would protect against this, not their CFI.

https://docs.microsoft.com/en-us/windows/threat-protection/windows-defender-application-guard/wd-app-guard-overview</div>
<div class='comment'>
<div class='author'>Unknown</div>
<div class='content'>They talk about both and explicitly names application guard too. There is a &quot;key findings&quot; area with one dot point about CFI and one about lack of RCE mitigations - &quot; We continue to make strides in preventing both Remote Code Execution (RCE) with mitigations like Control Flow Guard (CFG), export suppression, and Arbitrary Code Guard (ACG), and isolation, notably with Less Privileged AppContainer (LPAC) and Windows Defender Application Guard (WDAG).&quot;

They just mention CFI later again during exploitation discussion.</div>
</div>
<div class='comment'>
<div class='author'>Unknown</div>
<div class='content'>Sandboxing _does_ stop this sort of attack by locking down the renderer to a single origin. The other commenters brought up chrome&#39;s experimental site-isolation feature but it&#39;s mentioned in the article specifically about how it would stop this. They imply that edge already does this.

Did you not read the entire article before deciding to blog about its &#39;shortcomings&#39;? That&#39;s pretty funny.</div>
</div>
<div class='comment'>
<div class='author'>Robert</div>
<div class='content'>No, their post explicitly refers to CFI.</div>
</div>
<div class='comment'>
<div class='author'>Robert</div>
<div class='content'>Of course I read it. Can you quote where the article says (or implies) Edge has process-per-site isolation? I can&#39;t see it.

I don&#39;t think you can read the article as &quot;really being about sandboxing, not CFI&quot;. It&#39;s strongly focused on RCE: it has an entire section called &quot;The dangers of RCE&quot;, two of the four &quot;findings&quot; are about RCE, and most of the content is the details of achieving RCE. But sandboxing doesn&#39;t block RCE --- CFI does. And they don&#39;t even try to compare Chrome&#39;s sandbox vs Edge&#39;s, while they DO talk about Chrome&#39;s lack of CFI. Oh, and the entire post is titled &quot;Beyond Sandboxing&quot;!!!

I stand by what I wrote in my post. The attacks under &quot;the dangers of RCE&quot; in Microsoft&#39;s post are just as feasible without RCE and are not effectively mitigated by CFI, and therefore Microsoft&#39;s post is basically wrong.</div>
</div>
<div class='comment'>
<div class='author'>Robert</div>
<div class='content'>CFG and ACG are both forms of CFI.

LPAC and WDAG are both forms of sandboxing.

None of them would block the sort of data-only attack on Web security boundaries that I talked about.</div>
</div>
</div>
<div class='comment'>
<div class='author'>Unknown</div>
<div class='content'>That whole section &quot;dangers of RCE&quot; is about about how with RCE on chrome you can break same origin - this implies that Edge isn&#39;t vulnerable to this. You generally don&#39;t make a big deal about how you competitor is vulnerable to X while also being vulnerable to X. It&#39;s implied in the &quot;key findings&quot; area too.

I didn&#39;t say it was &quot;really about sandboxing&quot; but effective sandboxing is a part of mitigating same origin bypasses through some RCE bugs, like the one discussed in the article.

Sandboxing does stop RCE by reducing attack surface. You might not think of it in the same was as ASLR but it&#39;s for the same reason.</div>
<div class='comment'>
<div class='author'>Robert</div>
<div class='content'>If Edge has process-per-site isolation, and the author was aware that it&#39;s process-per-site isolation that&#39;s *really* preventing escalation of arbitary-read/write bugs to same-origin violations, why would they write an article focusing on RCE/CFI, which would be basically irrelevant in that case --- and never mention process-per-site isolation in Edge, even when they mention Chrome&#39;s? That would make the article grossly misleading.

FWIW a bunch of security people agreed with my interpretation. If Microsoft grossly misled us all, that&#39;s on them.

Process-boundary sandboxing doesn&#39;t stop RCE by the way. You sandbox to limit what an RCE can do after it has taken over the process.

This discussion is getting tedious. I&#39;ll try not to reply again.</div>
</div>
</div>
<div class='comment'>
<div class='author'>Peter Kasting</div>
<div class='content'>Also, we Chrome folks have had our eyes on this problem for several years, which the primary motivation for things like the OOPIF work; malware served in an ad frame should not be able to snoop data from the hosting page even if we have a renderer or JS engine bug.</div>
<div class='comment'>
<div class='author'>Robert</div>
<div class='content'>The text there still seems a bit vague --- &quot;We could choose to protect only a set of sensitive web sites, perhaps including those the user has logged into, or all HTTPS sites.&quot;

Protecting all HTTPS sites doesn&#39;t seem like it will mitigate the overhead of multiple processes very effectively in the world of &quot;HTTPS everywhere&quot;.

I guess we&#39;ll see how it goes when you ship!</div>
</div>
<div class='comment'>
<div class='author'>Robert</div>
<div class='content'>http://www.chromium.org/developers/design-documents/site-isolation says &quot;How to handle Chrome&#39;s renderer process limit remains an open question.&quot; Is that out of date?</div>
</div>
<div class='comment'>
<div class='author'>Robert</div>
<div class='content'>That&#39;s good, although it&#39;s still a long way to being able to reliably enforce one process per origin AFAICT.</div>
</div>
<div class='comment'>
<div class='author'>Robert</div>
<div class='content'>OK, but it&#39;s not what I would call &quot;reliable enforcement of one process per origin&quot; when only a (relatively small?) set of sites get the protection.</div>
</div>
<div class='comment'>
<div class='author'>Will</div>
<div class='content'>It&#39;s closer than you think. Try enabling it in chrome://flags/#enable-site-per-process - run latest Canary for best to experience. I run on all my machines with no issues but YMMV.</div>
</div>
<div class='comment'>
<div class='author'>Peter Kasting</div>
<div class='content'>No, the plan is below that: &quot;We are planning to initially protect only a set of opt-in, high-value sites.  We will expand this set as resource usage permits.&quot;</div>
</div>
<div class='comment'>
<div class='author'>Peter Kasting</div>
<div class='content'>Per the status there, there&#39;s a plan to handle it.  It&#39;s &quot;open&quot; in the sense that we&#39;d like to revisit the question over time to see if the plan was, and remains, the right one.

I agree with Will&#39;s assessment; site isolation in Chrome is pretty near at hand.</div>
</div>
</div>

</div>