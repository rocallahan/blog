---
layout: "post"
title: "Hazardous Biology"
date: "2009-02-18 10:00:00 +0000"
permalink: "/2009/02/hazardous-biology_18.html"
---
<div class="columns"><p><a href="http://radar.oreilly.com/2009/02/etech-preview-creating-biologi.html">This</a> is the scariest thing I've read in a long time. If the leading lights in synthetic biology are this naive, humanity is toast. The idea that we can prevent abuse while democratising access, by bonding researchers into a loving utopian community, is laughable. The comparison to computers is completely inappropriate. Thomas Lord's comment near the bottom is a pretty good summary of the problems here.<br/><p>I especially dislike the rhetorical technique that treats suppressing a technology as de facto absurd. On the contrary, if a technology poses a serious danger to humanity, then it absolutely should be suppressed, or at least tightly controlled and not "democratised". We've done it for nuclear weapons with moderate success.<br/><p>God have mercy on us.</div><br/><br/>
<div class='comments'><h2>Comments</h2>
<div class='comment'>
<div class='author'>anonymous reader</div>
<div class='content'>Those allow little more than painting pictures with glowing bacteria. Kids stuff. Kids that were doing basic chemical experiments in school aren&#39;t more likely to make explosives when they grow up. It&#39;s not comparable to nuclear warheads, more like smoke detectors.<br></div>
</div>
<div class='comment'>
<div class='author'>Eamon Nerbonne</div>
<div class='content'>In a probably doomed attempt to soothe your fears, I think Ms. Shetty is much closer to right than the doubters below her post.  The interview is just a teaser; it&#39;s not a complete explanation but a motivation.<br>The fears suggested are hollywood-stuff.  Rather than Thomas Lord, consider the immediately preceding comment of Roy Batty...  Why is a computer virus harmless in the wild?  Because pigs will fly before it&#39;ll run outside of a computer.<br>To a non-specialist, it might sound plausible that these bio-engineered organisms might &quot;take over the world&quot;, but in actual fact, the chance of that occurring is nonexistent.  There&#39;s all kinds of reasons why it&#39;s unlikely that&#39;ll occur, but consider that there are far more prosaic forms of far more dangerous bio-engineering which we constantly engage in with far less oversight and with far more dangerous repercussions: namely plain centuries old selective breeding, or the transport of invasive species.<br>Bio-engineered organisms are a Hollywood threat; lab-grown organisms are fragile and quite likely to succumb to infection or competition (and the more engineered they are, the less threatening they tend to be).<br>A software engineers instincts suggest that a subtle bug can cause widespread problems.  That&#39;s a problem caused by the utter lack of competition and the relative vaccuum in which software lives.<br>In biology?  If a simple fix could miraculously allow a particular strain such an advantage, it would exist.  The idea that humans might make a microorganism that can out-compete existing ones (outside of an engineered situation) is laughable.<br>I&#39;m a programmer; By happenstance many of my friends are from a medical or biological background, and a year ago I considered participating in a project much like what Ms. Shetty describes, so I looked into it a little.<br>That experience would lead me to believe that there&#39;s no cause for alarm.  If, at some time in the future, the state of the art advances and somewhat survivable organisms are possible...<br>Right now, the much less sexy plain old breeding still is much _much_ more likely to be dangerous.<br>Knowing the way these conversations go, I doubt I convinced you, but you never know...<br></div>
</div>
<div class='comment'>
<div class='author'>Robert O'Callahan</div>
<div class='content'>Equating the capabilities of evolution and a lab is a big mistake. Evolution is slow and in the wild, is subject to constraints like (for diseases) a host population that can evolve resistance. In a lab, those constraints can be artificially lowered. We could, for example, develop a pathogen (or a series) so different from existing ones that the target species can&#39;t evolve resistance in time to avoid being wiped out.<br></div>
</div>
<div class='comment'>
<div class='author'>Logan</div>
<div class='content'>What about accelerated evolution?<br>IIRC many more herbicide resistant plant strains have been created by deliberate but random disruption of DNA by radiation, than by deliberate ans specific modification.<br></div>
</div>
<div class='comment'>
<div class='author'>Damian</div>
<div class='content'>roc: I think your confusing evolution of macro life forms and micro life forms. Evolution of micro life forms is not all that slow in the wild.<br>Developing such a pathogen would probably require an understanding of biology we&#39;re not even close to. We&#39;ve been messing about with DNA manipulation for years, we can still barely come up with things that copy functions that nature already does.<br></div>
</div>
<div class='comment'>
<div class='author'>David</div>
<div class='content'>I agree with you, but the comparison with computers is totally appropriate.<br>Every technology bring catastrophies. always. The real question is : are we prepared for them ?<br>Are we prepared to deal with car/train/plane crashes ? yes I think we are.<br>Are we prepared to deal with computers crashes ? yes we definitely are.<br>Are we prepared to deal with biological crashes ? no we&#39;re not!<br>are we prepared to deal with the possibility that God doesn&#39;t exist ? yes we are. Are you Robert ? ;-)<br>sorry, i&#39;m a deep agnostic.<br></div>
</div>
<div class='comment'>
<div class='author'>Hanspeter</div>
<div class='content'>From the comment you praise in the original post: &quot;Synthbio is practically unique among the engineering fields in that it is pretty much always faced with the &quot;mistakes == end of humanity&quot; scenario.&quot;<br>This is _identical_ to the LHC fear-mongering from last year (http://hasthelargehadroncolliderdestroyedtheworldyet.com/)<br></div>
</div>
<div class='comment'>
<div class='author'>Aristotle Pagaltzis</div>
<div class='content'>I think suppression attempts and reasoned democratisation visions are both equally delusional. The only rational response, to me, seems to be to start research into mitigation long before it’s actually necessary. (It won’t produce the right answers now, but would evolve toward them alongside the development and adoption of the technology itself, and it might inform concurrent suppression or regulation attempts so they operate on substance instead of conjecture.)<br>I doubt that any of these three is going to happen.<br></div>
</div>
<div class='comment'>
<div class='author'>David</div>
<div class='content'>@Hanspeter : no it&#39;s not identical. it&#39;s totally different.<br>The LHC is about evaluating risks. The risk has been calculated to be less than what is happening in nature.<br>Biotech creates things that don&#39;t happen naturally. There _will_ be hyper-resistant bacterias. There _will_ be over-aggressive rats. There _will_ be carcinogen fungus. There _will_ be something bad I can&#39;t think of.<br>If you don&#39;t believe it, you&#39;re underestimating that technology.<br>There _will_ also be bad things happening with LHC, but not the monster black hole thing. Things we&#39;re prepared to deal with.<br>It&#39;s not fear. It&#39;s just how it goes. Every technology know catastrophies. And it happens sooner if the technology is democratized.<br>you&#39;re not digging a giant ring in your backyard. are you ?<br></div>
</div>
<div class='comment'>
<div class='author'>ander13</div>
<div class='content'>RESHMA SHETTY. Hindu. Repatriate Indian. DNA Hacker.<br></div>
</div>

</div>