---
layout: "post"
title: "Media Cache"
date: "2009-04-02 12:00:00 +0000"
categories: "Mozilla"
permalink: "/2009/04/media-cache_02.html"
---
<div class="columns"><p>I've just checked in the <a href="http://hg.mozilla.org/mozilla-central/rev/35879b7a23f9">media data cache</a> to Gecko trunk. It should appear in nightly builds tonight and on the 1.9.1 branch soon-ish. If you just can't wait to try it, there are try-server builds for <a href="https://build.mozilla.org/tryserver-builds/2009-03-31_21:44-rocallahan@mozilla.com-try-4de3c4ab9b1/rocallahan@mozilla.com-try-4de3c4ab9b1-firefox-try-linux.tar.bz2">Linux</a>, <a href="https://build.mozilla.org/tryserver-builds/2009-03-31_21:44-rocallahan@mozilla.com-try-4de3c4ab9b1/rocallahan@mozilla.com-try-4de3c4ab9b1-firefox-try-mac.dmg">Mac</a> and <a href="https://build.mozilla.org/tryserver-builds/2009-03-31_21:44-rocallahan@mozilla.com-try-4de3c4ab9b1/rocallahan@mozilla.com-try-4de3c4ab9b1-firefox-try-win32.zip">Windows</a>.<br/><p>Media applications want fast, "on demand" random access to media data, for pausing, seeking, etc --- something like the standard "seek/read" OS file APIs. But we are primarily interested in transporting media data using HTTP over the Internet, which has high latency to open a connection, requires a new connection for every seek, may not even support seeking on some connections (especially live streams), and uses a push model --- data comes from the server and you don't have much control over the rate. Also, transferring data over the Internet can be slow and/or unpredictable, so we want to read ahead to buffer and cache as much data as possible.<br/><p>The job of the media cache is to resolve this impedance mismatch. The media cache reads data from Necko channels into file-backed storage, and offers a random-access file-like API to the stream data (nsMediaCacheStream). Along the way it solves several problems:<br/><ul><br/><li>The cache intelligently reads ahead to prefetch data that may be needed in the future.<br/><li>The size of the cache is bounded so that we don't fill up storage with read-ahead data.<br/><li>The cache stores played data as well as read-ahead data so that backward seeks and replay can be served without redownload.<br/><li>Cache replacement is managed globally so that the most valuable data (across all streams) is retained.<br/><li>The cache can suspend Necko channels temporarily when their data is not wanted (yet).<br/><li>The cache translates file-like seek requests to HTTP seeks, including optimizations like not triggering a new seek if it would be faster to just keep reading until we reach the seek point, and adjusting the seek destination to avoid re-downloading data already in the cache. The "seek to EOF" idiom to determine file size is also handled efficiently (seeking to EOF and then seeking back to the previous offset does not trigger any Necko activity).<br/><li>The cache also handles the case where the server does not support seeking.<br/><li>Necko can only send data to the main thread, but nsMediaCacheStream can distribute data to any thread.<br/><li>The cache exposes APIs so clients can detect what data is currently cached.<br/></ul><br/><p>(Our previous strategy was incredibly naive: just read all the incoming data from the HTTP stream and store it in memory, and throw it away after it has been played once; seeks throw away all data and create a new HTTP stream.)<br/><p>Although HTTP is the most important transport and we only support transport-level seeking via HTTP byte-ranges, the media cache works with any kind of Necko channels and provides random access to cached data even for, e.g., FTP streams.<br/><p>The media cache is not persistent. It does not currently allow data from one load to be used by other loads, either within the same browser session or across browser sessions.<br/><p>The media cache is block-based. Streams are divided into blocks of a fixed size (currently 4K) and we cache blocks. A single cache contains blocks for all streams. The cache size is controlled by the media.cache_size preference (which is in KB). The default size is 50MB.<br/><p>The replacement policy predicts a "time of next use" for each block in the cache. When we need to free a block, the block with the latest "time of next use" will be evicted. Blocks are divided into different classes, each class having its own predictor:<br/><ul><br/><li>FREE_BLOCK: these blocks are effectively infinitely far in the future; a free block will always be chosen for replacement before other classes of blocks.<br/><li>METADATA_BLOCK: these are blocks that contain data that has been read by the decoder in "metadata mode", e.g. while the decoder is searching the stream during a seek operation. These blocks are managed with an LRU policy; the "time of next use" is predicted to be as far in the future as the last use was in the past.<br/><li>PLAYED_BLOCK: these are blocks that have not been read in "metadata mode", and contain data behind the current decoder read point. (They may not actually have been read by the decoder, if the decoder seeked forward.) These blocks are managed with an LRU policy except that we add REPLAY_DELAY seconds of penalty to their predicted "time of next use", to reflect the uncertainty about whether replay will actually happen or not.<br/><li>READAHEAD_BLOCK: these are blocks that have not been read in "metadata mode" and that are entirely ahead of the current decoder read point. (They may actually have been read by the decoder in the past if the decoder has since seeked backward.) We predict the time of next use for these blocks by assuming steady playback and dividing the number of bytes between the block and the current decoder read point by the decoder's estimate of its playback rate in bytes per second. This ensures that the blocks farthest ahead are considered least valuable.<br/></ul><br/><p>For efficient prediction of the "latest time of next use", we maintain linked lists of blocks in each class, ordering blocks by time of next use. READAHEAD_BLOCKS have one linked list per stream, since their time of next use depends on stream parameters, but the other lists are global.<br/><p>"Time of next use" estimates are also used for flow control. When reading ahead we can predict the time of next use for the data that will be read. If the predicted time of next use is later then the prediction for all currently cached blocks, and the cache is full, then we should suspend reading from the Necko channel.<br/><p>Unfortunately suspending the Necko channel can't immediately stop the flow of data from the server. First our desire to suspend has to be transmitted to the server (in practice, Necko stops reading from the socket, which causes the kernel to shrink its advertised TCP receive window size to zero). Then the server can stop sending the data, but we will receive data roughly corresponding to the product of the link bandwidth multiplied by the round-trip latency. We deal with this by letting the cache overflow temporarily and then trimming it back by moving overflowing blocks back into the body of the cache, replacing less valuable blocks as they become available. We try to avoid simply discarding overflowing readahead data.<br/><p>All changes to the actual contents of the cache happen on the main thread, since that's where Necko's notifications happen.<br/><p>The media cache maintains at most one Necko channel for each stream. (In the future it might be advantageous to relax this, e.g. so that a seek to near the end of the file can happen without disturbing the loading of data from the beginning of the file.) The Necko channel is managed through nsMediaChannelStream; nsMediaCache does not depend on Necko directly.<br/><p>Every time something changes that might affect whether we want to read from a Necko channel, or whether we want to seek on the Necko channel --- such as data arriving or data being consumed by the decoder --- we asynchronously trigger nsMediaCache::Update on the main thread. That method implements most cache policy. It evaluates for each stream whether we want to suspend or resume the stream and what offset we should seek to, if any. It is also responsible for trimming back the cache size to its desired limit by moving overflowing blocks into the main part of the cache. The policy mechanism is fairly simple and stateless; it examines the current state of the cache and of all consumers, and decides what each stream should do at this moment (i.e., should the stream be trying to read data and if so, at what offset should it be trying to read).<br/><p>Streams can be opened in non-seekable mode. In non-seekable mode, the cache will only call nsMediaChannelStream::CacheClientSeek with a 0 offset. The cache tries hard not to discard readahead data for non-seekable streams, since that could trigger a potentially disastrous re-read of the entire stream. It's up to cache clients to try to avoid requesting seeks on such streams.<br/><p>The media cache is primarily designed to support HTML5 media elements, but potentially it could be useful in other places where we want a mix of random and sequential access to large files accessed over HTTP.</div><br/><br/>
<div class='comments'><h2>Comments</h2>
<div class='comment'>
<div class='author'>sam</div>
<div class='content'>This is great! So I can safely assume to see higher performance in online video (e.g. Flash video) in the next Firefox release?<br></div>
</div>
<div class='comment'>
<div class='author'>Funtomas</div>
<div class='content'>That&#39;s great improvement. It might pave the way for media downloading in Bittorrent-like fashion, i.e. from various sources, right? Any API to tweak the cache (e.g. total size, block size, playback time of preloaded content, etc.)? Any API to rebuild the media file from the blocks so it can be saved permanently after the session terminates?<br></div>
</div>
<div class='comment'>
<div class='author'>Robert O'Callahan</div>
<div class='content'>sam: this won&#39;t do anything for Flash, it&#39;s only used by our HTML5 media support (Wave, Ogg Vorbis and Ogg Theora right now).<br>Funtomas: It would be quite a lot of work to retrofit something like Bittorrent into this, to be honest. The cache size is controlled from a preference which is accessible via about:config. Tweaking the block size probably isn&#39;t useful. Some of the tuning parameters could be turned into preferences, I suppose, but I don&#39;t know of any benefit for doing that. Extracting and saving the media data would be possible but in most cases you can just right-click on the video and do &quot;Save As...&quot; to either save it from the Necko cache or re-download for saving, if necessary.<br></div>
</div>
<div class='comment'>
<div class='author'>Alfred Kayser</div>
<div class='content'>This makes video handling in Firefox much better!<br>As tested with Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.2a1pre) Gecko/20090402 Minefield/3.6a1pre (.NET CLR 3.5.30729), jumping around in a video (on TinyVid.tv) no longer reloads the video, but directly plays from that point (unless jumped to a part no loaded yet).<br></div>
</div>
<div class='comment'>
<div class='author'>Mook</div>
<div class='content'>This sounds great!  Will this be usable by non-libxul consumers, as a general thing exposed by necko or some other module?  (The checkin seems to just have nsMediaCache.h which doesn&#39;t look exposed)<br>Would I be correct to assume it still uses the normal necko http cache, i.e. if it happens to be cachable, it will?<br></div>
</div>
<div class='comment'>
<div class='author'>Robert O'Callahan</div>
<div class='content'>Mook, because of the seeking that happens, you normally won&#39;t see media objects being stored in the Necko cache. I&#39;m not sure what the best way is to fix that.<br>What would you want to use this for outside of libxul? You can use media elements outside of libxul, obviously.<br></div>
</div>
<div class='comment'>
<div class='author'>fred</div>
<div class='content'>How does this handle non-http protocols? ie. ftp or file://<br>Is there any special handling for SSL? How does this relate to the ability to watch requests using somthing like adblock plus?<br></div>
</div>
<div class='comment'>
<div class='author'>fred</div>
<div class='content'>I thought the necko cache was only designed for very small objects.. (hence why putting images in it was a bad idea) or have I confused it for something else?<br></div>
</div>
<div class='comment'>
<div class='author'>Alfred Kayser</div>
<div class='content'>Fred: the images are cached in a special way. That is why there are not any more in the necko cache. The necko cache can handle large objects (at large in terms of pictures).<br>The caching of images is not really caching but holding the image in memory for a while after the pages referring to it have released the image.<br></div>
</div>

</div>